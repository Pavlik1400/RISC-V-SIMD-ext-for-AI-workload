{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.utils import reload_module\n",
    "from datasets.fabric import make_sigmod_ds\n",
    "import numpy as np\n",
    "reload_module(\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(name, path, *args, **kwargs):\n",
    "    ds = make_sigmod_ds(name, *args, **kwargs)\n",
    "    ds.load(path)\n",
    "    print(ds.get_data().shape)\n",
    "    print(ds.get_labels().shape)\n",
    "    splitted_ds = ds.split_train_val_test(0.8, 0.1)\n",
    "    print(ds.get_split_indecies()[0].shape)\n",
    "    print(len(np.unique(ds.get_split_indecies()[0])))\n",
    "    print(len(splitted_ds.train.labels))\n",
    "    print(len(splitted_ds.val.labels))\n",
    "    print(len(splitted_ds.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset(\"radioml_2016\", \"data/radioml_2016/RML2016.10a_dict.pkl\")\n",
    "# test_dataset(\n",
    "#     \"matlab_v2\", \"data/simc_v2_30k_fpm_0_30_snr/\", frames_per_modulation=30_000, snrs=range(0, 30)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "radioml_ds = make_sigmod_ds(\"radioml_2016\")\n",
    "radioml_ds.load(\"data/radioml_2016/RML2016.10a_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.fabric import make_sigmod_model, ConvolutionConfiguration\n",
    "\n",
    "# cnn_v1_configuration = ConvolutionConfiguration(\n",
    "#     input_shape=(1, 128, 2),\n",
    "#     n_classes=len(radioml_ds.get_modulations()),\n",
    "#     output_channels=[32, 48, 64, 96, 128, 192],\n",
    "#     kernel_sizes=[8, 8, 8, 8, 8, 8],\n",
    "#     paddings=[\"same\", \"same\", \"same\", \"same\", \"same\", \"same\"],\n",
    "#     max_pool_sizes=[1, 1, 2, 1, 2, 1],\n",
    "#     max_pool_strides=[1, 1, 2, 1, 2, 1],\n",
    "#     avg_size=32,\n",
    "#     dense_sizes=[],\n",
    "# )\n",
    "\n",
    "# model = make_sigmod_model(\"cnn_1d_v1\", cnn_v1_configuration)\n",
    "\n",
    "# model.summary()\n",
    "# splitted_radioml_ds = radioml_ds.split_train_val_test(0.8, 0.1)\n",
    "# print(splitted_radioml_ds.train.data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:55:55.088905: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-29 22:55:55.113627: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 22:55:55.509367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-29 22:55:55.891582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:55.907554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:55.908504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:55.918946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:55.919040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:55.919097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:56.302139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:56.302251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:56.302314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 22:55:56.302377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5971 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 2)]          0         \n",
      "                                                                 \n",
      " CNN0_ (Conv1D)              (None, 128, 32)           544       \n",
      "                                                                 \n",
      " RELU0_ (ReLU)               (None, 128, 32)           0         \n",
      "                                                                 \n",
      " ENC1_ (SigModEncoder)       (None, 128, 32)           50816     \n",
      "                                                                 \n",
      " AVG1_ (AveragePooling1D)    (None, 4, 32)             0         \n",
      "                                                                 \n",
      " FLT1_ (Flatten)             (None, 128)               0         \n",
      "                                                                 \n",
      " FC0_ (Dense)                (None, 128)               16512     \n",
      "                                                                 \n",
      " FC_RELU0_ (ReLU)            (None, 128)               0         \n",
      "                                                                 \n",
      " FC_2_ (Dense)               (None, 11)                1419      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 11)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,291\n",
      "Trainable params: 69,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(1, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "from models.fabric import make_sigmod_model, EncoderTransformerConfiguration, EncoderLayerConfiguration\n",
    "\n",
    "enc_v1_configuration = EncoderTransformerConfiguration(\n",
    "    input_shape=(128, 2),\n",
    "    n_classes=len(radioml_ds.get_modulations()),\n",
    "    \n",
    "    cnn_output_channels=[32],\n",
    "    cnn_kernel_sizes=[8],\n",
    "    cnn_paddings=[\"same\"],\n",
    "    \n",
    "    encoder_layer=EncoderLayerConfiguration(\n",
    "        h=4,\n",
    "        d_k=32,\n",
    "        d_v=32,\n",
    "        d_model=32,\n",
    "        d_ff=128,\n",
    "        n=4,\n",
    "    ),\n",
    "    \n",
    "    avg_size=32,\n",
    "    dense_sizes=[128],\n",
    ")\n",
    "\n",
    "model = make_sigmod_model(\"encoder_transformer_1d_v1\", enc_v1_configuration)\n",
    "model.summary()\n",
    "splitted_radioml_ds = radioml_ds.split_train_val_test(0.8, 0.1)\n",
    "print(splitted_radioml_ds.train.data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176000, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# TODO: remove this inconsistency\n",
    "splitted_radioml_ds.train.data = np.squeeze(splitted_radioml_ds.train.data)\n",
    "splitted_radioml_ds.val.data = np.squeeze(splitted_radioml_ds.val.data)\n",
    "splitted_radioml_ds.test.data = np.squeeze(splitted_radioml_ds.test.data)\n",
    "\n",
    "print(splitted_radioml_ds.train.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:56:01.197400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-29 22:56:01.708868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-29 22:56:01.799191: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f99e1902830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-29 22:56:01.799207: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti Laptop GPU, Compute Capability 8.6\n",
      "2023-06-29 22:56:01.802279: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-29 22:56:01.882747: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 44s 27ms/step - loss: 1.7908 - accuracy: 0.3188 - val_loss: 1.4164 - val_accuracy: 0.4440 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "1375/1375 [==============================] - 36s 26ms/step - loss: 1.3632 - accuracy: 0.4705 - val_loss: 1.3747 - val_accuracy: 0.4714 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "1375/1375 [==============================] - 37s 27ms/step - loss: 1.2942 - accuracy: 0.5035 - val_loss: 1.2816 - val_accuracy: 0.5157 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "1375/1375 [==============================] - 37s 27ms/step - loss: 1.2407 - accuracy: 0.5250 - val_loss: 1.2361 - val_accuracy: 0.5315 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "1375/1375 [==============================] - 38s 27ms/step - loss: 1.2144 - accuracy: 0.5364 - val_loss: 1.1896 - val_accuracy: 0.5451 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "1375/1375 [==============================] - 38s 27ms/step - loss: 1.1957 - accuracy: 0.5452 - val_loss: 1.1906 - val_accuracy: 0.5436 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "1375/1375 [==============================] - 38s 28ms/step - loss: 1.1800 - accuracy: 0.5516 - val_loss: 1.1709 - val_accuracy: 0.5569 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "1375/1375 [==============================] - 40s 29ms/step - loss: 1.1688 - accuracy: 0.5593 - val_loss: 1.1936 - val_accuracy: 0.5601 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "1375/1375 [==============================] - 40s 29ms/step - loss: 1.1153 - accuracy: 0.5851 - val_loss: 1.1246 - val_accuracy: 0.5835 - lr: 1.0000e-04\n",
      "Epoch 10/40\n",
      "1375/1375 [==============================] - 40s 29ms/step - loss: 1.1074 - accuracy: 0.5887 - val_loss: 1.1193 - val_accuracy: 0.5835 - lr: 1.0000e-04\n",
      "Epoch 11/40\n",
      "1375/1375 [==============================] - 40s 29ms/step - loss: 1.1038 - accuracy: 0.5899 - val_loss: 1.1235 - val_accuracy: 0.5821 - lr: 1.0000e-04\n",
      "Epoch 12/40\n",
      "1375/1375 [==============================] - 41s 30ms/step - loss: 1.1009 - accuracy: 0.5922 - val_loss: 1.1184 - val_accuracy: 0.5855 - lr: 1.0000e-04\n",
      "Epoch 13/40\n",
      "1375/1375 [==============================] - 41s 30ms/step - loss: 1.0975 - accuracy: 0.5942 - val_loss: 1.1114 - val_accuracy: 0.5887 - lr: 1.0000e-04\n",
      "Epoch 14/40\n",
      "1375/1375 [==============================] - 41s 30ms/step - loss: 1.0961 - accuracy: 0.5946 - val_loss: 1.1120 - val_accuracy: 0.5878 - lr: 1.0000e-04\n",
      "Epoch 15/40\n",
      "1375/1375 [==============================] - 43s 31ms/step - loss: 1.0938 - accuracy: 0.5962 - val_loss: 1.1111 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 16/40\n",
      "1375/1375 [==============================] - 42s 31ms/step - loss: 1.0914 - accuracy: 0.5975 - val_loss: 1.1134 - val_accuracy: 0.5883 - lr: 1.0000e-04\n",
      "Epoch 17/40\n",
      "1375/1375 [==============================] - 43s 31ms/step - loss: 1.0843 - accuracy: 0.6001 - val_loss: 1.1039 - val_accuracy: 0.5926 - lr: 1.0000e-05\n",
      "Epoch 18/40\n",
      "1375/1375 [==============================] - 42s 30ms/step - loss: 1.0827 - accuracy: 0.6009 - val_loss: 1.1056 - val_accuracy: 0.5920 - lr: 1.0000e-05\n",
      "Epoch 19/40\n",
      "1375/1375 [==============================] - 42s 30ms/step - loss: 1.0828 - accuracy: 0.6010 - val_loss: 1.1028 - val_accuracy: 0.5925 - lr: 1.0000e-05\n",
      "Epoch 20/40\n",
      "1375/1375 [==============================] - 42s 30ms/step - loss: 1.0828 - accuracy: 0.6015 - val_loss: 1.1038 - val_accuracy: 0.5917 - lr: 1.0000e-05\n",
      "Epoch 21/40\n",
      "1375/1375 [==============================] - 42s 31ms/step - loss: 1.0825 - accuracy: 0.6010 - val_loss: 1.1034 - val_accuracy: 0.5911 - lr: 1.0000e-05\n",
      "Epoch 22/40\n",
      "1375/1375 [==============================] - ETA: 0s - loss: 1.0818 - accuracy: 0.6010"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = 0.001\n",
    "    factor = epoch // 8\n",
    "    lrate /= 10**factor\n",
    "    return lrate\n",
    "\n",
    "\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "\n",
    "model.compile(\n",
    "    # optimizer=tf.keras.optimizers.Adam(learning_rate=0.0),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# N_EPOCHS = 16\n",
    "# BATCH_SIZE = 256\n",
    "N_EPOCHS = 40\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "h = model.fit(\n",
    "    splitted_radioml_ds.train.data,\n",
    "    splitted_radioml_ds.train.labels,\n",
    "    epochs=N_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(splitted_radioml_ds.val.data, splitted_radioml_ds.val.labels),\n",
    "    callbacks=[lrate]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
